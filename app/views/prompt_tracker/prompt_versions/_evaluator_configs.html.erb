<div class="card">
  <div class="card-header d-flex justify-content-between align-items-center">
    <div>
      <h5 class="mb-0">
        <i class="bi bi-robot"></i> Auto-Evaluators
      </h5>
      <small class="text-muted">
        Automatically evaluate every tracked LLM response from this version
      </small>
    </div>
    <button type="button" class="btn btn-sm btn-primary" data-bs-toggle="modal" data-bs-target="#addEvaluatorModal">
      <i class="bi bi-plus-circle"></i> Add Evaluator
    </button>
  </div>
  <div class="card-body">
    <!-- Info Alert -->
    <div class="alert alert-info mb-3">
      <h6 class="alert-heading"><i class="bi bi-info-circle"></i> How Auto-Evaluators Work</h6>
      <ul class="mb-0">
        <li><strong>Automatic execution:</strong> These evaluators run automatically on every LLM response generated from this prompt version</li>
        <li><strong>Tracked calls only:</strong> Auto-evaluators only run on production tracked calls (via <code>track_llm_call</code>), not on test runs</li>
        <li><strong>Real-time monitoring:</strong> Get instant quality scores for production responses without manual intervention</li>
      </ul>
    </div>

    <% if @version.evaluator_configs.any? %>
      <!-- Aggregation Strategy -->
      <div class="alert alert-secondary mb-3">
        <strong>Score Aggregation:</strong>
        <span class="badge bg-primary"><%= @prompt.score_aggregation_strategy&.titleize || "Weighted Average" %></span>
        <small class="d-block mt-1">
          <% case @prompt.score_aggregation_strategy %>
          <% when "weighted_average" %>
            Overall score is calculated using weighted average based on evaluator weights.
          <% when "simple_average" %>
            Overall score is the simple average of all evaluations (equal weight).
          <% when "minimum" %>
            Overall score is the minimum score across all evaluations (all must pass).
          <% when "custom" %>
            Overall score uses custom business logic.
          <% else %>
            Overall score is calculated using weighted average (default).
          <% end %>
        </small>
      </div>

      <!-- Evaluator Configs Table -->
      <div class="table-responsive">
        <table class="table table-hover">
          <thead>
            <tr>
              <th style="width: 5%;">
                <i class="bi bi-sort-numeric-down" title="Priority"></i>
              </th>
              <th style="width: 25%;">Evaluator</th>
              <th style="width: 15%;">Weight</th>
              <th style="width: 10%;">Mode</th>
              <th style="width: 15%;">Dependency</th>
              <th style="width: 10%;">Status</th>
              <th style="width: 20%;">Actions</th>
            </tr>
          </thead>
          <tbody>
            <% @version.evaluator_configs.by_priority.each do |config| %>
              <tr class="<%= 'table-secondary' unless config.enabled? %>">
                <td class="text-center">
                  <span class="badge bg-secondary"><%= config.priority %></span>
                </td>
                <td>
                  <strong><%= config.name %></strong>
                  <br>
                  <small class="text-muted"><%= config.description %></small>
                </td>
                <td>
                  <div class="d-flex align-items-center">
                    <div class="progress flex-grow-1 me-2" style="height: 20px;">
                      <div class="progress-bar" role="progressbar"
                           style="width: <%= (config.weight * 100).round(1) %>%"
                           aria-valuenow="<%= (config.weight * 100).round(1) %>"
                           aria-valuemin="0" aria-valuemax="100">
                        <%= (config.weight * 100).round(1) %>%
                      </div>
                    </div>
                  </div>
                  <% if @prompt.score_aggregation_strategy == "weighted_average" %>
                    <small class="text-muted">
                      Normalized: <%= (config.normalized_weight * 100).round(1) %>%
                    </small>
                  <% end %>
                </td>
                <td>
                  <% if config.sync? %>
                    <span class="badge bg-success">
                      <i class="bi bi-lightning-fill"></i> Sync
                    </span>
                  <% else %>
                    <span class="badge bg-info">
                      <i class="bi bi-clock"></i> Async
                    </span>
                  <% end %>
                </td>
                <td>
                  <% if config.has_dependency? %>
                    <span class="badge bg-warning text-dark" title="Requires <%= config.depends_on %> >= <%= config.min_dependency_score || 80 %>">
                      <i class="bi bi-link-45deg"></i> <%= config.depends_on %>
                    </span>
                    <br>
                    <small class="text-muted">â‰¥ <%= config.min_dependency_score || 80 %></small>
                  <% else %>
                    <span class="text-muted">None</span>
                  <% end %>
                </td>
                <td>
                  <% if config.enabled? %>
                    <span class="badge bg-success">
                      <i class="bi bi-check-circle"></i> Enabled
                    </span>
                  <% else %>
                    <span class="badge bg-secondary">
                      <i class="bi bi-x-circle"></i> Disabled
                    </span>
                  <% end %>
                </td>
                <td>
                  <button type="button" class="btn btn-sm btn-outline-primary" onclick="editEvaluatorConfig(<%= config.id %>)">
                    <i class="bi bi-pencil"></i> Edit
                  </button>
                  <%= button_to prompt_evaluator_config_path(@prompt, config),
                                method: :delete,
                                data: { confirm: "Are you sure you want to remove this evaluator?" },
                                class: "btn btn-sm btn-outline-danger" do %>
                    <i class="bi bi-trash"></i> Remove
                  <% end %>
                </td>
              </tr>
            <% end %>
          </tbody>
        </table>
      </div>

      <!-- Weight Distribution Summary -->
      <% if @prompt.score_aggregation_strategy == "weighted_average" %>
        <div class="alert alert-light mt-3">
          <strong>Total Weight:</strong> <%= @version.evaluator_configs.enabled.sum(:weight).round(2) %>
          <% total_weight = @version.evaluator_configs.enabled.sum(:weight) %>
          <% if total_weight > 0 %>
            <span class="text-success">
              <i class="bi bi-check-circle"></i> Weights will be normalized
            </span>
          <% else %>
            <span class="text-warning">
              <i class="bi bi-exclamation-triangle"></i> No enabled evaluators with weight
            </span>
          <% end %>
        </div>
      <% end %>
    <% else %>
      <div class="text-center py-5">
        <i class="bi bi-robot text-muted" style="font-size: 3rem;"></i>
        <p class="text-muted mt-3">No auto-evaluators configured yet.</p>
        <p class="text-muted">Add evaluators to automatically evaluate production responses from this version.</p>
        <button type="button" class="btn btn-primary" data-bs-toggle="modal" data-bs-target="#addEvaluatorModal">
          <i class="bi bi-plus-circle"></i> Add Your First Auto-Evaluator
        </button>
      </div>
    <% end %>
  </div>
</div>
