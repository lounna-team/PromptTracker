# frozen_string_literal: true

# == Schema Information
#
# Table name: prompt_tracker_dataset_rows
#
#  created_at :datetime         not null
#  dataset_id :bigint           not null
#  id         :bigint           not null, primary key
#  metadata   :jsonb            not null
#  row_data   :jsonb            not null
#  source     :string           default("manual"), not null
#  updated_at :datetime         not null
#
module PromptTracker
  # Represents a single row of test data within a dataset.
  #
  # Each row contains variable values that match the dataset's schema.
  # Rows can be created manually, generated by LLMs, or imported from external sources.
  #
  # @example Create a manual row
  #   row = dataset.dataset_rows.create!(
  #     row_data: { customer_name: "Alice", issue: "billing" },
  #     source: "manual"
  #   )
  #
  # @example Create an LLM-generated row
  #   row = dataset.dataset_rows.create!(
  #     row_data: { customer_name: "Bob", issue: "refund" },
  #     source: "llm_generated",
  #     metadata: { generation_prompt: "Create edge case scenarios" }
  #   )
  #
  class DatasetRow < ApplicationRecord
    # Constants
    SOURCES = %w[manual llm_generated imported].freeze

    # Associations
    belongs_to :dataset,
               class_name: "PromptTracker::Dataset",
               inverse_of: :dataset_rows

    has_many :prompt_test_runs,
             class_name: "PromptTracker::PromptTestRun",
             dependent: :nullify,
             inverse_of: :dataset_row

    # Delegate to get prompt_version through dataset
    has_one :prompt_version, through: :dataset

    # Validations
    validates :row_data, presence: true
    validates :source, presence: true, inclusion: { in: SOURCES }

    validate :row_data_must_be_hash
    validate :row_data_matches_schema

    # Scopes
    scope :recent, -> { order(created_at: :desc) }
    scope :manual, -> { where(source: "manual") }
    scope :llm_generated, -> { where(source: "llm_generated") }
    scope :imported, -> { where(source: "imported") }

    # Callbacks
    after_create_commit :broadcast_prepend_to_dataset
    after_update_commit :broadcast_replace_to_dataset
    after_destroy_commit :broadcast_remove_to_dataset

    # Get variable value
    #
    # @param variable_name [String, Symbol] the variable name
    # @return [Object] the variable value
    def get_variable(variable_name)
      row_data[variable_name.to_s]
    end

    # Set variable value
    #
    # @param variable_name [String, Symbol] the variable name
    # @param value [Object] the variable value
    def set_variable(variable_name, value)
      self.row_data = row_data.merge(variable_name.to_s => value)
    end

    private

    # Broadcast prepend to dataset rows table
    def broadcast_prepend_to_dataset
      broadcast_prepend_to(
        "dataset_#{dataset_id}_rows",
        target: "dataset-rows",
        partial: "prompt_tracker/testing/datasets/row",
        locals: { row: self, index: dataset.dataset_rows.count, dataset: dataset }
      )

      # Remove empty state if this is the first row
      if dataset.dataset_rows.count == 1
        broadcast_remove_to(
          "dataset_#{dataset_id}_rows",
          target: "empty-state"
        )
      end
    end

    # Broadcast replace to dataset rows table
    def broadcast_replace_to_dataset
      broadcast_replace_to(
        "dataset_#{dataset_id}_rows",
        target: "dataset-row-#{id}",
        partial: "prompt_tracker/testing/datasets/row",
        locals: { row: self, index: dataset.dataset_rows.where("id <= ?", id).count, dataset: dataset }
      )
    end

    # Broadcast remove from dataset rows table
    def broadcast_remove_to_dataset
      broadcast_remove_to(
        "dataset_#{dataset_id}_rows",
        target: "dataset-row-#{id}"
      )
    end

    # Validate that row_data is a hash
    def row_data_must_be_hash
      return if row_data.nil? || row_data.is_a?(Hash)

      errors.add(:row_data, "must be a hash")
    end

    # Validate that row_data matches dataset schema
    def row_data_matches_schema
      return if dataset.blank? || dataset.schema.blank?
      return unless row_data.is_a?(Hash) # Skip if row_data is not a hash (handled by row_data_must_be_hash)

      schema_variable_names = dataset.variable_names
      row_variable_names = row_data.keys

      # Check for missing required variables
      required_vars = dataset.schema.select { |v| v["required"] == true }.map { |v| v["name"] }
      missing_vars = required_vars - row_variable_names

      if missing_vars.any?
        errors.add(:row_data, "missing required variables: #{missing_vars.join(', ')}")
      end

      # Check for extra variables not in schema
      extra_vars = row_variable_names - schema_variable_names

      if extra_vars.any?
        errors.add(:row_data, "contains unknown variables: #{extra_vars.join(', ')}")
      end
    end
  end
end
